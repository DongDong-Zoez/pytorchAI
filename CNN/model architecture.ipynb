{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model architecture.ipynb","provenance":[],"mount_file_id":"1gUIpx-2WFsqdQwHsVzL50wRVwHdThr1J","authorship_tag":"ABX9TyNPV1dJePcoVenjrbaOttVO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# State-of-the-Art model architecture\n","\n","本文將會介紹所有你需要知道的 CNN 模型，概念其實大同小異\n","\n","## CNN 架構\n","\n","- 影像分類: 特徵提取器 (feature extractor) + 分類器 (classifier)\n","- 影像分割: 網路骨幹 (backbone) + 全卷機網路 (fully connected network)\n","- 物件偵測: 網路骨幹 (backbone) + 分類器 (classifier)\n","\n","### 影像分類任務\n","\n","- LeNet、AlexNet、[VGG16]()，主要為 feature extractor + classifier\n","- [ResNet](https://arxiv.org/pdf/1512.03385.pdf)，利用 residual block 的方式讓網路做的更深\n","  - Identical residual block\n","  - Convolution residual block\n","  - BasisBlock\n","  - Bottleneck\n","  - ResNeXt: 簡化 Inception + GConv\n","- [DenseNet](https://arxiv.org/pdf/1608.06993.pdf)，利用 concat 的方式讓網路做的更深\n","  - Bottleneck layers\n","  - Compression\n","- [MobileNet](https://arxiv.org/pdf/1704.04861.pdf)，利用 DW + PW 輕量化網路\n","  - V1 $\\to$ deepthwise + pointwise\n","    - deepthwise: 一種維度為 ```in_channels``` 的捲機做為特徵提取\n","    - pointwise: ```in_channels``` 種維度為  ```out_channels``` 的 1x1 捲機做為特徵組合\n","  - V2 $\\to$ Expansion layer、Linear Bottlenck\n","    - Expansion layer: 低維度映射到高維度，可以想像成 unzip\n","    - Linear Bottlencek: 對低維空間做 relu 會損失信息，所以用 linear activation function\n","  - V3 $\\to$ SE、h-swish\n","- [SPP](https://arxiv.org/pdf/1406.4729.pdf) 多尺度分割後池化\n","- [ASPP](https://arxiv.org/pdf/1606.00915v2.pdf) 空洞捲機、Sum fusion\n","- [Inception](https://arxiv.org/pdf/1409.4842.pdf)\n","  - V1 $\\to$ 1x1、3x3、5x5、MaxPool2d 並行抓取特徵 (GoogLeNet)\n","  - V2 $\\to$ 2 個 3x3 代替 5x5，利用 1xn 搭配 nx1 代替 nxn\n","  - V3 $\\to$ 輔助分類器使用 BN、使用 label smoothing\n","  - V4 $\\to$ Inception + Resdual connection (Inception-ResNet)\n","- [Xception](https://arxiv.org/pdf/1610.02357.pdf) 先用 1x1 捲機操作，之後把輸出的通道分別接上 3x3 捲機後連接\n","- [ShuffleNet](https://arxiv.org/pdf/1807.11164.pdf) \n","  - V1 $\\to$ GConv + channel shuffle\n","    - GConv: 將特徵圖、捲機核按照通道分組，分別計算後連接\n","    - channel shuffle: 進一步將 GConv 分組後的特徵圖再分組，保證每個組別都含有其他組別的信息\n","  - V2 $\\to$ 優化網路建議、設計新的 block\n","    - 輸入維度盡可能等於輸出維度\n","    - 不能無腦增大 group 數\n","    - 網路不能太多分枝\n","    - 盡可能減少 element-wise 操作\n","- [SEnet](https://arxiv.org/pdf/1709.01507.pdf) feature recalibration\n","  - feature recalibration: 對於每一個特徵圖預測一個常數，做為特徵圖的權重\n","- [PolyNet](https://arxiv.org/pdf/1611.05725.pdf) 將 Inception 模塊中的 conv 換成 Inception 模塊，並且共享權值\n","- [NASNet](https://arxiv.org/pdf/1707.07012.pdf) 利用 PPO 自主學習網路 Block，但整體網路還需要自己定義\n","  - Normal Cell: 輸入特徵圖和輸出特徵圖大小一致\n","  - Reduction Cell: 對輸入特徵圖執行一次降採樣 (捲機 stride 預設為 2)\n","  - 步驟:\n","    - 第 $h_i$ 層 layers 之前的輸出選一個做為 hidden layer A 的輸入\n","    - 第 $h_i$ 層 layers 之前的輸出選一個做為 hidden layer B 的輸入\n","    - 為 A 的 feature map 選擇一個運算 (分離捲機、空洞捲機、捲機...)\n","    - 為 B 的 feature map 選擇一個運算 (分離捲機、空洞捲機、捲機...)\n","    - 選擇 add 或者 concat 方法合併 A 和 B\n","- [AmoebaNet](https://arxiv.org/pdf/1802.01548.pdf) 延續 NASNet，自主學習網路架構\n","  - 步驟:\n","    - 隨機初始化 P 個個體 (網路) 加入族群，訓練後驗證網路精度，將 P 個個體加入歷史族群\n","    - 若歷史族群數量少於 C，則從族群隨機抽取 S 個樣本，從中選出精度最高的做為父個體\n","    - 對父個體變異後得到子個體，訓練後驗證子個體網路精度\n","    - 將子個體加入歷史族群和族群中，從族群中淘汰最老的個體 (非精度最差)\n","    - 重複上述步驟直到歷史族群數量大過 C，最後選出精度最高的網路\n","  - 變異方式 (一個子網路包含 5 個 Block):\n","    - 改變 Block 的輸入 (hidden layer) 或操作 (空洞捲機、池化...) (二選一)\n","    - 選一種 Block 類型 (Normal cell or Reduction cell) (二選一)\n","    - 選一個 Block 進行變體 (五選一)\n","    - 選一個 Block 的輸入分支 (hidden layer A or hidden layer B) (二選一)\n","    - 使用第一步驟選出的輸入變體或操作對 Block 做變異\n","- [EfficientNet](https://arxiv.org/pdf/1905.11946.pdf) 在資源有限的情況下調整 resolution、depth、weight 來獲得最佳模型\n","  - depth: $d=\\alpha^\\phi$\n","  - width: $w=\\beta^\\phi$\n","  - resolution $r=\\gamma^\\phi$\n","  - constraint to $\\alpha*\\beta^2*\\gamma^2 \\approx 2$ and $\\alpha, \\beta, \\gamma \\geq 1$\n","  - 步驟:\n","    - 固定 $\\phi=1$，利用 grid search 找最優 $\\alpha, \\beta, \\gamma$\n","    - 固定 $\\alpha, \\beta, \\gamma$，更改 $\\phi$ 生成 EfficientNetB1~B7\n","\n"],"metadata":{"id":"mxYwqyTdw-Vq"}},{"cell_type":"markdown","source":["# ResNet"],"metadata":{"id":"JEC91WwY2-LO"}},{"cell_type":"code","source":["import torchvision"],"metadata":{"id":"nOVXrbxpK2VR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torchvision.models.resnet50()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YB_zROXgK5kf","executionInfo":{"status":"ok","timestamp":1653216493974,"user_tz":-480,"elapsed":759,"user":{"displayName":"8787 Zoez","userId":"17680164657657523368"}},"outputId":"829bb036-5f4d-4381-c508-2b7bfce62119"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["import torch.nn as nn\n","class BottleNeck(nn.Module):\n","\n","    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n","        super().__init__()\n","\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_channels),\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n","        self.bn2 = nn.BatchNorm2d(out_channels),\n","        self.conv3 = nn.Conv2d(out_channels, in_channels, kernel_size=1, stride=1, padding=0),\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.downsample = downsample\n","\n","    def forward(self, x):\n","\n","        identity = x\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x = self.conv3(x)\n","\n","        if self.downsample:\n","            x = self.downsample(x) + identity\n","        x = self.relu(x)\n","        \n","        return x\n","\n","class ResNet(nn.Module):\n","\n","    def __init__(self, block, layers, num_classes):\n","        super().__init__()\n","\n","        self.in_channels = 3\n","        out_channels = 64\n","\n","        self.conv1 = nn.Conv2d(self.in_channels, out_channels, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","\n","        self.in_channels = out_channels\n","\n","        self.layer1 = self._make_layer(block, 256, layers[0], 1)\n","        self.layer2 = self._make_layer(block, 32, layers[1], 2)\n","        self.layer3 = self._make_layer\n","\n","        self.avg_pool = nn.AvgPool2d(8,ceil_mode=False)\n","        self.fc = nn.Linear(64, num_classes)\n","\n","    def _make_layer(self, block, out_channels, num_blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.in_channels != out_channels:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","        \n","        layers = []\n","        layers.append(block(self.in_channels, out_channels, stride, downsample))\n","        self.in_channels = out_channels\n","\n","        for i in range(num_blocks):\n","            layers.append(block(out_channels, out_channels))\n","        return nn.Sequential(*layers)\n","\n","\n","\n","        "],"metadata":{"id":"WwjBHyoFMIL1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","\n","class CBR(nn.Module):\n","\n","    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n","        super().__init__()\n","\n","        self.layers = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        return self.layers(x)\n","\n","class IRB(nn.Module):\n","\n","    def __init__(self, in_channels, out_channels, activation=nn.ReLU()):\n","        super().__init__()\n","\n","        assert in_channels == out_channels\n","\n","        self.layers = nn.Sequential(\n","            CBR(in_channels, out_channels, 3, 1, 1),\n","            CBR(out_channels, out_channels, 3, 1, 1),\n","\n","            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n","            nn.BatchNorm2d(out_channels)\n","        )\n","\n","        self.activation = activation\n","\n","    def forward(self, x):\n","        identity = x\n","        x = self.layers(x)\n","        x = x + identity\n","        x = self.activation(x)\n","        return x\n","\n","  \n"," class CRB(nn.Module):\n","\n","    def __init__(self, in_channels, out_channels, activation=nn.ReLU()):\n","        super().__init__()\n","\n","        self.layers = nn.Sequential(\n","            CBR(in_channels, out_channels, 3, 1, 1),\n","            CBR(out_channels, out_channels, 3, 1, 1),\n","\n","            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n","            nn.BatchNorm2d(out_channels)\n","        )\n","\n","        self.activation = activation\n","\n","    def forward(self, x):\n","        identity = x\n","        x = self.layers(x)\n","        x = x + identity\n","        x = self.activation(x)\n","        return x       "],"metadata":{"id":"om2K2sp5X68f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"tlqcL4ZbX23l"},"execution_count":null,"outputs":[]}]}