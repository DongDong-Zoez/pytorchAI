{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CRFs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOA6me2xsfurMBAR5FAD31N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DongDong-Zoez/pytorchAI/blob/main/CRFs/CRFs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conditional Random Fields\n",
        "\n",
        "條件隨機場是一個統計應用於神經網路的方法，他可以用於影像分割、自然語言處理等等，通常會接在網路後端對影像或者文字做進一步的優化，這裡我們著重介紹 CRFs 在影像分割上的用途"
      ],
      "metadata": {
        "id": "bYFDsGnr1nbw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From Log Linear Model to CRFs\n",
        "\n",
        "我們回憶我們學到的 log linear model 定義為 \n",
        "\n",
        "$$p(y|x)=\\frac{1}{Z(x)}\\exp\\sum_{k=1}^Kw_kF_k(x,y)$$\n",
        "\n",
        "- $Z(x)=\\sum_y\\exp\\sum_{k=1}^Kw_kF_k(x,y)$ 被稱作標準化因子 (normalized factor)，其作用保證機率值介於 $[0,1]$ 區間，且在同一個 $x$ 下有 $\\sum_xp(y|x)=1$ \n",
        "\n",
        "- $F(x, y)$ 稱作特徵函數 (feature function)，用以衡量 $x$ 和 $y$ 共同出現的適配程度\n",
        "\n",
        "CRFs 可以看做是 Log Linear Model 的一種，他把特徵函數定義為 $F(x,y)=\\sum_{i=2}^nf_k(y_{i-1}, y_i,x,i)$\n",
        "\n",
        "## From HMM to CRFs\n",
        "\n",
        "另一種代入 CRFs 的看法可以從 HMM (Hiden Markov Model) 講起，HMM 是個生成模型且定義如下\n",
        "\n",
        "$$p(x,y)=p(y)p(x|y)=\\prod_{t=1}^Tp(y_t|y_{t-1})p(x_t|y_t)$$\n",
        "\n",
        "- $x_t$ 為觀測值，$y_t$ 為隱藏態 (hidden state)\n",
        "- 馬可夫假設當前狀態 (current state) $y_t$ 只被前狀態 (previous state) 影響 $y_{t-1}$\n",
        "- $p(y_t|y_{t-1})$ 被稱作轉移機率 (transition probability)，表示狀態之間轉移的可能性\n",
        "- $p(x_t|y_t)$ 被稱作排放機率 (emission probability)，表因當前狀態而產生 (排出) 觀測值 $x_t$ 的可能性\n",
        "\n",
        "不難看出，上式第一個等號為條件機率，其中 $y=\\{y_1,\\cdots, y_t\\}$ 為狀態序列，第二個等號表示從第一個狀態轉移到最後一個狀態的機率，乘上狀態產生觀測值的機率\n"
      ],
      "metadata": {
        "id": "8p4wNMSQyfzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![https://i.stack.imgur.com/khcnl.png](https://i.stack.imgur.com/khcnl.png)"
      ],
      "metadata": {
        "id": "kf6_t3Ns4F2o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CRFs\n",
        "\n",
        "我們回頭看看 CRFs 的特徵函數\n",
        "\n",
        "- $p(y|x)=\\frac{1}{Z(x)}\\exp\\sum_k w_k\\sum_i f_k(y_{i-1}, y_i,x,i)$\n",
        "- $\\sum_i f_k(y_{i-1}, y_i,x,i)$ 代表在馬可夫假設下的任意子結構, 更精確的說, 給定一個觀測值 $x$, 他可以與任意隱狀態 $y_i$ 相關, 且馬可夫自然條件假設 $y_i$ 與 $y_{i-1}$ 相關\n",
        "- Linear-chain CRFs 允許觀測值之間的任意連接\n",
        "- $i$ 是一個強力參數，可用來考慮狀態的時間位置\n",
        "- $w_k$ 用以衡量特徵函數的重要性，可以透過梯度下降學習"
      ],
      "metadata": {
        "id": "ZqGK1cdT4qoU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CRFs In CV\n",
        "\n",
        "我們來講講在電腦視覺領域上的 CRFs 如何建模，回憶我們前文所提，我們意旨於找到一個隱藏序列可以最大化給定觀測值的機率，即\n",
        "\n",
        "$$\n",
        "\\arg\\max_y p(y|x)\n",
        "$$\n",
        "\n",
        "在影像分割領域中\n",
        "\n",
        "- Consider an image $I$ with $n$ pixels segmentate to $k$ classes\n",
        "- Model the segmentation to a random field $X=\\{X_1,\\cdots, X_n\\}$ where $X_i$ takes value in $1,\\cdots,k$\n",
        "- $y:$ 影像分割的 Output\n",
        "- $x:$ 原影像\n",
        "- Let $C$ be a clique, $X_C$ be the observation data in $C$\n",
        "- $p(X)=\\frac{1}{Z}\\prod_C\\psi_C(X_C)$ where potential function is defined as $\\psi_C(X_C)=e^{-E(X_C)}$ and $E(X_C)=\\sum_i\\psi_u(x_i)+\\sum_{i<j}\\psi_p(x_i, x_j)$\n",
        "\n",
        "### Energy function\n",
        "\n",
        "- $E(X_C)=\\sum_i\\psi_u(x_i)+\\sum_{i<j}\\psi_p(x_i, x_j)$\n",
        "- The value of energy function indicates that the degree of stationary of the state (lower value indicate stationary)\n",
        "- $\\sum_i\\psi_u(x_i):$ the pixels assign the wrong labels $(|X_C|=1)$\n",
        "- $\\sum_{i<j}\\psi_p(x_i, x_j):$ all the pair of points assign different labels $(|X_C|=2)$\n",
        "\n",
        "注意到在能量函數中，unary potential 通常為 CNN 模型的輸出，pairwise potential 則是需要去決定的函數\n",
        "\n",
        "### MF Inference"
      ],
      "metadata": {
        "id": "CSxMg_S7BQk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://i.imgur.com/PHFHzHk.jpg)"
      ],
      "metadata": {
        "id": "aXtHceTQCnU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 直覺上怎麼說?\n",
        "\n",
        "看了這麼多數學，都快吐了，我們來看看直覺上 CRFs 代給我們什麼?\n",
        "\n",
        "![](https://i.imgur.com/uwUVOtS.png)\n",
        "\n",
        "- (a) 原影像\n",
        "- (b) 將影像的 pixel 點建模成隨機場的形式\n",
        "- (c) 通過 CNN 得到 unary output (這時有些點被分錯) (unary potential)\n",
        "\n",
        "<details>\n",
        "<summary>為什麼會分錯呢? 點擊查看解答</summary>\n",
        "CNN 只關注 local 範圍的物件\n",
        "</details>\n",
        "\n",
        "- (d) 這時候我們可以根據影像的一些特徵，如 pixel 之間的亮度，位置等等去懲罰那些分錯的點 (pairwise potential)"
      ],
      "metadata": {
        "id": "_RVCjXcoDNQ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FullCRFs\n",
        "\n",
        "- $\\psi_p(x_i,x_j|I)=\\mu(x_i,x_j)\\sum_{m=1}^Mw^{(m)}k^{(w)}_G(f_i^I,f_j^I)$\n",
        "- $w^{(m)}$ are the learnable parameters of model\n",
        "- $k(f_i^I,f_j^I)=\\\\w^{(1)}\\exp(-\\frac{|p_i-p_j|^2}{2\\theta_\\alpha^2}-\\frac{|I_i-I_j|^2}{2\\theta_\\beta^2})+w^{(2)}\\exp(-\\frac{|p_i-p_j|^2}{2\\theta_\\gamma^2})$\n",
        "- $w^{(1)}, w^{(2)},\\theta_\\alpha, \\theta_\\beta, \\theta_\\gamma$ are learnable parameters\n",
        "- ConvCRFs complains that the message passing is the bottleneck of CRF with $O(\\mbox{number of pixels}^2)$ time complexity\n",
        "\n",
        "### ConvCRFs\n",
        "\n",
        "- Consider an image $I$ with $n$ pixels segmentate to $k$ classes\n",
        "- Model the segmentation to a random field $X=\\{X_1,\\cdots, X_n\\}$ where $X_i$ takes value in $1,\\cdots,k$\n",
        "- Goal: solve $\\arg\\max_XP(X|I)$\n",
        "- $P(X|I)$ is modeled as $P(X=\\hat x|I=\\tilde I)=\\frac{1}{Z(I)}\\exp(-E(\\hat x|I))$ where $E(\\hat x|I)=\\sum_{}\\psi_u(\\hat x_i|I)+\\sum_{i\\neq j\\leq N}\\psi_p(\\hat x_i,\\hat x_j|I)$\n",
        "\n",
        "### What's New?\n",
        "\n",
        "- ConvCRFs assume that pair of pixels $i,j$ are joint independent if Manhattan distance $d(i,j)>k$ (You may regard $k$ as the filter size)\n",
        "- Others word, $\\sum_{i\\neq j\\leq N}\\psi_p(x_i,x_j)=0$ if $d(i,j)>k$\n",
        "- reformulate message passing function to truncated Gaussian kernel\n",
        "\n",
        "### Kernel function\n",
        "\n",
        "- consider input $P$ with shape $[bs,c,h,w]$, the Gaussian kernel $g$ defined by feature vectors $f_1,\\cdots,f_d$ each with shape $[bs,h,w]$\n",
        "- $k_g[bs,dx,dy,x,y]=\\\\ \\exp(-\\sum_{i=1}^d\\frac{|f_i^{(d)}[bs,x,y]-f^{(d)}_i[bs,x-dx,y-dy]|^2}{2\\theta_i^2})$\n",
        "- where $\\theta_i$ are learnable parameters\n",
        "- Merge gaussian kernel $K=\\sum_{i=1}^sw_ig_i$\n",
        "- In practice, $f_i$ is choose to be the RGB intensity and spatial location $x,y$ ($s=2$)\n"
      ],
      "metadata": {
        "id": "TU1E9e3XtCXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Note: The animation evaluation of ConvCRFs can be founded at https://dongdong-zoez.github.io/sources/ConvCRFs/index.html"
      ],
      "metadata": {
        "id": "tXP4SyxMtyzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset\n",
        "\n",
        "以下網站是大神提供的 [SBD](https://www.sun11.me/blog/2018/how-to-use-10582-trainaug-images-on-DeeplabV3-code/) 資料集，trainaug.txt 可以從 [這](https://gist.githubusercontent.com/sun11/2dbda6b31acc7c6292d14a872d0c90b7/raw/5f5a5270089239ef2f6b65b1cc55208355b5acca/trainaug.txt) 拿到，SBD 是 Segmentation 領域最常用來衡量模型表現的資料，算是 Pascal VOC 的數據增廣版本\n",
        "\n",
        "我們會用到以下資料\n",
        "\n",
        "- train: SBD dataset (Pascal VOC dataset) with 10582 images (trainaug)\n",
        "- val  : Pascal VOC 2012 val with 1449 images\n",
        "\n",
        "以下專案提供了 [ConvCRFs](https://arxiv.org/pdf/1805.04777.pdf) 的訓練代碼"
      ],
      "metadata": {
        "id": "ohzXc41JFMRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp7AjpCWHFSt",
        "outputId": "7bc4534a-2f06-4516-c79c-5efb4e97a26a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive')\n",
        "!git clone https://github.com/DongDong-Zoez/ConvCRFs-training.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXn3TUvuSsEG",
        "outputId": "f78ccdab-528e-430c-e50c-f347cb2b9903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ConvCRFs-training' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/gdrive/MyDrive')\n",
        "!python /content/gdrive/MyDrive/ConvCRFs-training/main.py --data-path '/content/gdrive/MyDrive' -b 1 --epochs 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq7BtIG-Psqv",
        "outputId": "e1f9c889-54d6-4cab-b2c5-a369a47cbacb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;94mdevice\u001b[0m: cuda\n",
            "\u001b[1;94mbatch size\u001b[0m: 1\n",
            "\u001b[1;94mnum workers\u001b[0m: 0\n",
            "\u001b[1;94mlearning rate\u001b[0m: 5e-05\n",
            "\u001b[1;94mloss function\u001b[0m: CrossEntropy\n",
            "\u001b[1;94moptimizer\u001b[0m: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    initial_lr: 5e-05\n",
            "    lr: 5e-05\n",
            "    maximize: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "\u001b[1;94mscaler\u001b[0m: None\n",
            "\u001b[1;94mepochs\u001b[0m: 1\n",
            "\u001b[1;94mweight decay\u001b[0m: 0.0005\n",
            "\u001b[1;94mlr_scheduler\u001b[0m: PolynomialScheduler\n",
            "\u001b[1;94mstart epochs\u001b[0m: 0\n",
            "\u001b[1;94maux\u001b[0m: False\n",
            "\u001b[1;94mcrf\u001b[0m: False\n",
            "\u001b[1;94mfullscaleFeat\u001b[0m: None\n",
            "\u001b[1;94mheld out images\u001b[0m: 10\n",
            "\u001b[1;94mtrain with held out\u001b[0m: True\n",
            "\u001b[1;94mnum train images\u001b[0m: 10\n",
            "\u001b[1;94mnum val images\u001b[0m: 1449\n",
            "\u001b[1;94mnum steps per epoch\u001b[0m: 10\n",
            "\u001b[1;94mtrain transfrom\u001b[0m: [RandomResize, RandomCrop, RandomHorizontalFilp, RandomRotate, ToTensor, Normalize]\n",
            "\u001b[1;94mval transforms\u001b[0m: [Resize, ToTensor, Normalize]\n",
            "\n",
            "Epoch: [0]  [ 0/10]  eta: 0:00:20  lr: 0.000045  loss: 3.3752 (3.3752)  time: 2.0921  data: 0.0355  max mem: 2069\n",
            "Epoch: [0] Total time: 0:00:05\n",
            "Test:  [  0/363]  eta: 0:02:48    time: 0.4655  data: 0.0811  max mem: 2671\n",
            "Test:  [100/363]  eta: 0:02:01    time: 0.4770  data: 0.0685  max mem: 2671\n",
            "Test:  [200/363]  eta: 0:01:18    time: 0.4890  data: 0.0683  max mem: 2671\n",
            "Test:  [300/363]  eta: 0:00:30    time: 0.4874  data: 0.0716  max mem: 2671\n",
            "Test: Total time: 0:02:54\n",
            "global correct: 33.78\n",
            "average row correct: ['41.2', '0.0', '0.1', '0.1', '0.2', '0.2', '0.0', '94.8', '0.0', '1.1', '0.6', '0.3', '1.8', '0.2', '0.0', '38.7', '2.2', '5.7', '0.1', '0.1', '0.5']\n",
            "IoU: ['40.4', '0.0', '0.0', '0.1', '0.1', '0.1', '0.0', '3.5', '0.0', '0.6', '0.3', '0.2', '1.0', '0.1', '0.0', '14.4', '0.4', '0.7', '0.1', '0.1', '0.2']\n",
            "mean IoU: 2.97\n",
            "training time 0:03:03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rwX3mkQDhNZ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}